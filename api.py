#criaÃ§Ã£o da api / substitui o main/
#bash na pasta do cod / 

from fastapi import FastAPI
from pydantic import BaseModel
import os
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# ðŸ”§ Carregar variÃ¡veis de ambiente
load_dotenv()

app = FastAPI(title="PDF Agent API")

# ðŸ§  Carregar FAISS e LLM
vectorstore_path = os.getenv("VECTORSTORE_FOLDER", "./vectordb/faiss_index")

print("ðŸ“¦ Carregando FAISS index...")
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

vectorstore = FAISS.load_local(
    vectorstore_path,
    embeddings,
    allow_dangerous_deserialization=True
)

retriever = vectorstore.as_retriever()
llm = ChatGroq(model="llama-3.3-70b-versatile")

# ðŸ§© Prompt atualizado â€” para forÃ§ar resposta explicativa + fonte
prompt = ChatPromptTemplate.from_template(
    """VocÃª Ã© um assistente que responde perguntas com base em documentos PDF.
Leia o contexto abaixo e elabore uma resposta clara, completa e direta Ã  pergunta.
Ao final da resposta, cite a fonte (nome do PDF e pÃ¡gina), caso disponÃ­vel.

Contexto:
{context}

Pergunta:
{question}

Responda de forma explicativa, e no final acrescente algo como:
'Fonte: [nome do arquivo], pÃ¡gina X'."""
)

# ðŸ”— FunÃ§Ã£o que adiciona metadados visÃ­veis, mas de forma leve
def format_docs(docs):
    formatted = []
    for d in docs:
        source = d.metadata.get("source", "Fonte desconhecida")
        page = d.metadata.get("page", "pÃ¡gina desconhecida")
        formatted.append(
            f"Trecho do arquivo {os.path.basename(source)}, pÃ¡gina {page}:\n{d.page_content}"
        )
    return "\n\n".join(formatted)

# ðŸ”— Montagem do pipeline
chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
)

# ðŸ“© Modelo da requisiÃ§Ã£o
class QuestionRequest(BaseModel):
    question: str

# ðŸ“¤ Endpoint principal
@app.post("/ask")
async def ask_question(request: QuestionRequest):
    resposta = chain.invoke(request.question)
    return {"answer": resposta.content}
